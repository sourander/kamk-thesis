{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7e9ec06",
   "metadata": {},
   "source": [
    "# Merge the CDC Files to Bronze\n",
    "\n",
    "Note that in Databricks, we could use the Auto Loader. In this case, our **readStream** would have additional options:\n",
    "\n",
    "```python\n",
    " .format(\"cloudFiles\")\n",
    " .option(\"cloudFiles.format\", \"parquet\")\n",
    " .option(\"cloudFiles.useNotifications\", \"true\") # Use for SQS/SNS\n",
    " .option(\"cloudFiles.region\", \"eu-west-1\")      # Use for SQS/SNS\n",
    "```\n",
    "\n",
    "My thesis includes examples of this in Finnish. This script uses file listing method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c8621f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pprint\n",
    "import pyspark.sql.functions as F\n",
    "from helpers.paths import PathMerger\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52978122",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName(\"MergeCDCtoBronze\")\n",
    "         .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.0.0\")\n",
    "         .config('spark.sql.extensions', \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "         .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "         .config('spark.sql.session.timeZone', 'UTC')\n",
    "         .getOrCreate())\n",
    "\n",
    "\n",
    "# This cannot be imported before initializing the SparkSession.\n",
    "from delta import DeltaTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c68258",
   "metadata": {},
   "source": [
    "## Imagine orchestator here\n",
    "\n",
    "If this was a worker Notebook in Databricks, or a worker Python script orchestrated by Airflow the parameters below would be fed while executing this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbcfcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "db, table = \"devices\", \"device_models\"\n",
    "all_pks = [\"id\"]\n",
    "\n",
    "# Init\n",
    "pm = PathMerger(db, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f18939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The following Parquet files exist in this staging path: \n",
      "S3\\staging\\dms\\abc\\devices\\device_models\\LOAD00000001.parquet\n",
      "S3\\staging\\dms\\abc\\devices\\device_models\\2021\\9\\5\\20210905_095611.parquet\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] The following Parquet files exist in this staging path: \")\n",
    "\n",
    "for f in glob.glob(pm.staging + os.sep + \"**/*.parquet\", recursive=True):\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b80e0d",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "Based on my testing, the pathGlobFilter applies to the filename, not to the whole path. \n",
    "\n",
    "Thus, a glob filter such as...\n",
    "* `**/*.parquet` returns no files\n",
    "* `[L]*.parquet` returns all files starting with an `L` letter and ending to `.parquet`.\n",
    "* `[!L]*.parquet` returns all files NOT starting with an `L` letter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b66f9b",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dda0cce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_ordering_cols(input_df, batch_id):\n",
    "    output_df = ( \n",
    "        input_df\n",
    "        .withColumn(\"op_numeral\", F.when(F.col(\"Op\") == \"I\", 1)\n",
    "                                     .when(F.col(\"Op\") == \"U\", 2)\n",
    "                                     .when(F.col(\"Op\") == \"D\", 3).cast(\"int\"))\n",
    "        .withColumn('dms_temp', F.to_timestamp(F.col(\"dms_timestamp\")))\n",
    "        #.withColumn(\"par\", F.col(\"*all_pks[0]) % n_pars)\n",
    "        #.withColumn(\"src_file\", F.input_file_name())\n",
    "        .withColumn(\"src_batch_id\", F.lit(batch_id).cast(\"int\"))\n",
    "    )\n",
    "    return output_df \n",
    "\n",
    "\n",
    "def log_compact(input_df, cols_to_drop=[\"aaa\", \"bbb\"]):\n",
    "    output_df = (\n",
    "        input_df\n",
    "            .selectExpr(*all_pks, \"struct(dms_temp as aaa, op_numeral as bbb, *) as others\")\n",
    "            .groupBy(*all_pks)\n",
    "            .agg(F.max(\"others\").alias(\"latest\"))\n",
    "            .select(\"latest.*\")\n",
    "            .drop(*cols_to_drop)\n",
    "        \n",
    "    )\n",
    "    return output_df\n",
    "\n",
    "\n",
    "def merge_to_delta(batch_df, batch_id):\n",
    "    \n",
    "    # Add op_numeral and dms_temp\n",
    "    batch_df = with_ordering_cols(batch_df, batch_id)\n",
    "    \n",
    "    # Compact change log to one item per id\n",
    "    latest_uniques = log_compact(batch_df)\n",
    "    \n",
    "    # Load Delta Table\n",
    "    target = DeltaTable.forName(spark, pm.hive)\n",
    "    \n",
    "    # Using target schema, format to: { \"id\": \"s.id\" }\n",
    "    col_map = {x.name: f\"s.{x.name}\" for x in target.toDF().schema}\n",
    "    \n",
    "    # Format the list of primary keys \n",
    "    # into SQL join condition like \"t.id = s.id AND t.foo = s.foo\"\n",
    "    join_cond = \" AND \".join([f\"t.{pk} = s.{pk}\" for pk in all_pks])\n",
    "    \n",
    "    (\n",
    "      target.alias(\"t\")\n",
    "      .merge(\n",
    "          latest_uniques.alias(\"s\"),\n",
    "            f\"{join_cond}\")\n",
    "            .whenMatchedDelete(condition = \"s.Op = 'D'\")\n",
    "            .whenMatchedUpdate(condition = \"s.Op = 'U'\", set = col_map)\n",
    "            .whenNotMatchedInsert(condition = \"s.Op != 'D'\", values = col_map)\n",
    "      .execute()\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620a164",
   "metadata": {},
   "source": [
    "## Restore to VERSION 0\n",
    "\n",
    "To make sure that this Notebook is idempotent, let's always start from version 0.\n",
    "\n",
    "Another benefit is that we will have a Hive table available. The Hive in single-node test environment is not persistent, so we will need to create a new database and a new (EXTERNAL) table each time we restart our Python kernel and create a new SparkSession.\n",
    "\n",
    "In production, this would not be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df459fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "\n",
    "df_full_load = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(pm.bronze)\n",
    "\n",
    "(\n",
    "    df_full_load\n",
    "    .write\n",
    "    .format('delta')\n",
    "    .mode('overwrite')\n",
    "    .option('overwriteSchema', 'true')\n",
    "    .option('path', os.path.abspath(pm.bronze))\n",
    "    .saveAsTable(pm.hive)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d0d6a",
   "metadata": {},
   "source": [
    "## Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c9a762f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Schema is forced to match the Bronze, but with an extra field. DMS does not add Op to full load.\n",
    "readers_schema = spark.read.format(\"delta\").load(pm.bronze).schema.add(\"Op\", \"string\")\n",
    "\n",
    "# Checkpoints will be written to...\n",
    "checkpoint_path = os.path.join('S3', 'bronze', '_checkpoints', 'abc', db, table)\n",
    "\n",
    "\n",
    "# Prepare Spark Auto Loader\n",
    "df = ( spark.readStream\n",
    "        .format(\"parquet\")\n",
    "        .option(\"recursiveFileLookup\", \"true\")\n",
    "        .option(\"pathGlobFilter\", \"[!L][!O][!A][!D]*.parquet\")\n",
    "        .schema(readers_schema)\n",
    "        .load(pm.staging)\n",
    "  )\n",
    "\n",
    "\n",
    "# Stream\n",
    "streamingquery = ( \n",
    "    df\n",
    "    .writeStream\n",
    "    .trigger(once=True)\n",
    "    .foreachBatch(merge_to_delta)\n",
    "    # .option(\"checkpointLocation\", os.path.abspath(checkpoint_path))\n",
    "    .start()\n",
    ")\n",
    " \n",
    "streamingquery.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "df993501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batchId': 0,\n",
      " 'durationMs': {'addBatch': 3070,\n",
      "                'getBatch': 4,\n",
      "                'latestOffset': 143,\n",
      "                'queryPlanning': 7,\n",
      "                'triggerExecution': 3510,\n",
      "                'walCommit': 141},\n",
      " 'id': '991ad2c1-b433-4b46-9549-c2f1a780beb7',\n",
      " 'inputRowsPerSecond': 0.0,\n",
      " 'name': None,\n",
      " 'numInputRows': 8,\n",
      " 'processedRowsPerSecond': 2.2792022792022792,\n",
      " 'runId': 'e14d412d-9de3-4fae-a148-69682682625b',\n",
      " 'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1},\n",
      " 'sources': [{'description': 'FileStreamSource[file:/C:/Users/soura/PycharmProjects/opinnaytetyo/S3/staging/dms/abc/devices/device_models]',\n",
      "              'endOffset': {'logOffset': 0},\n",
      "              'inputRowsPerSecond': 0.0,\n",
      "              'numInputRows': 8,\n",
      "              'processedRowsPerSecond': 2.2792022792022792,\n",
      "              'startOffset': None}],\n",
      " 'stateOperators': [],\n",
      " 'timestamp': '2021-09-05T08:36:09.450Z'}\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "# Print what the query performed\n",
    "pp.pprint(streamingquery.lastProgress)\n",
    "\n",
    "# Use for forging the compacted DataFrame later on\n",
    "bid = streamingquery.lastProgress['batchId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789f5781",
   "metadata": {},
   "source": [
    "# Examine before-after compaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d07b65",
   "metadata": {},
   "source": [
    "### Bronze before Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "882ac4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>description</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>src_batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-04 11:10:50</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Red</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-04 11:10:50</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Black</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-04 11:10:50</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Pink</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-08-05 07:00:00</td>\n",
       "      <td>2010-08-05 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-04 11:10:50</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>Super Gadget 200</td>\n",
       "      <td>White</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2018-03-20 12:01:01</td>\n",
       "      <td>2018-03-20 12:01:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dms_timestamp  id release_date              name  color  description  \\\n",
       "0  2021-09-04 11:10:50   1   2010-05-15  Super Gadget 100    Red  lorem ipsum   \n",
       "1  2021-09-04 11:10:50   2   2010-05-15  Super Gadget 100  Black  lorem ipsum   \n",
       "2  2021-09-04 11:10:50   3   2010-11-01  Super Gadget 100   Pink  lorem ipsum   \n",
       "3  2021-09-04 11:10:50   4   2018-05-13  Super Gadget 200  White  lorem ipsum   \n",
       "\n",
       "              created            modified  src_batch_id  \n",
       "0 2010-03-21 12:00:01 2010-03-21 12:00:01           NaN  \n",
       "1 2010-03-21 12:00:02 2010-03-21 12:00:02           NaN  \n",
       "2 2010-08-05 07:00:00 2010-08-05 07:00:00           NaN  \n",
       "3 2018-03-20 12:01:01 2018-03-20 12:01:01           NaN  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the VERSION 0 - The original FULL LOAD.\n",
    "df_full_load.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b4718",
   "metadata": {},
   "source": [
    "### CDC Before Log Compaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a6dfbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op</th>\n",
       "      <th>dms_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>description</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>2021-09-05 09:55:48</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>Super Gadget 300</td>\n",
       "      <td>Black</td>\n",
       "      <td>new device</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>2021-09-05 09:55:48</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>Super Gadget 300</td>\n",
       "      <td>Pink</td>\n",
       "      <td>new device</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>2021-09-05 09:55:54</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Red</td>\n",
       "      <td>update A</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>2021-09-05 06:55:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>2021-09-05 09:55:54</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Black</td>\n",
       "      <td>update B</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>2021-09-05 06:55:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Op        dms_timestamp  id release_date              name  color  \\\n",
       "0  I  2021-09-05 09:55:48   5   2021-08-01  Super Gadget 300  Black   \n",
       "1  I  2021-09-05 09:55:48   6   2021-08-01  Super Gadget 300   Pink   \n",
       "2  U  2021-09-05 09:55:54   1   2010-05-15  Super Gadget 100    Red   \n",
       "3  U  2021-09-05 09:55:54   2   2010-05-15  Super Gadget 100  Black   \n",
       "\n",
       "  description             created            modified  \n",
       "0  new device 2021-09-05 06:55:48 2021-09-05 06:55:48  \n",
       "1  new device 2021-09-05 06:55:48 2021-09-05 06:55:48  \n",
       "2    update A 2010-03-21 12:00:01 2021-09-05 06:55:54  \n",
       "3    update B 2010-03-21 12:00:02 2021-09-05 06:55:54  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the original files from staging.\n",
    "df_cdc = spark.read.option(\"recursiveFileLookup\", \"true\").option(\"pathGlobFilter\", \"[!L][!O][!A][!D]*.parquet\").load(pm.staging)\n",
    "\n",
    "#Show\n",
    "df_cdc.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84494b37",
   "metadata": {},
   "source": [
    "### CDC After Log Compaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "eeeb3d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Op</th>\n",
       "      <th>dms_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>description</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>op_numeral</th>\n",
       "      <th>dms_temp</th>\n",
       "      <th>src_batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>2021-09-05 09:55:48</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>Super Gadget 300</td>\n",
       "      <td>Pink</td>\n",
       "      <td>new device</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-05 09:55:48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>2021-09-05 09:55:48</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>Super Gadget 300</td>\n",
       "      <td>Black</td>\n",
       "      <td>new device</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "      <td>2021-09-05 06:55:48</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-05 09:55:48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>2021-09-05 09:55:54</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Red</td>\n",
       "      <td>update A</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>2021-09-05 06:55:54</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-05 09:55:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>2021-09-05 09:55:54</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Black</td>\n",
       "      <td>update B</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>2021-09-05 06:55:54</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-05 09:55:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Op        dms_timestamp  id release_date              name  color  \\\n",
       "0  I  2021-09-05 09:55:48   6   2021-08-01  Super Gadget 300   Pink   \n",
       "1  I  2021-09-05 09:55:48   5   2021-08-01  Super Gadget 300  Black   \n",
       "2  U  2021-09-05 09:55:54   1   2010-05-15  Super Gadget 100    Red   \n",
       "3  U  2021-09-05 09:55:54   2   2010-05-15  Super Gadget 100  Black   \n",
       "\n",
       "  description             created            modified  op_numeral  \\\n",
       "0  new device 2021-09-05 06:55:48 2021-09-05 06:55:48           1   \n",
       "1  new device 2021-09-05 06:55:48 2021-09-05 06:55:48           1   \n",
       "2    update A 2010-03-21 12:00:01 2021-09-05 06:55:54           2   \n",
       "3    update B 2010-03-21 12:00:02 2021-09-05 06:55:54           2   \n",
       "\n",
       "             dms_temp  src_batch_id  \n",
       "0 2021-09-05 09:55:48             0  \n",
       "1 2021-09-05 09:55:48             0  \n",
       "2 2021-09-05 09:55:54             0  \n",
       "3 2021-09-05 09:55:54             0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add ordering columns and perform compaction\n",
    "df_latest_uniques = log_compact(with_ordering_cols(df_cdc, bid))\n",
    "\n",
    "# Show\n",
    "df_latest_uniques.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15042a5",
   "metadata": {},
   "source": [
    "### Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "11ee6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+------------+----------------+-----+-----------+-------------------+-------------------+------------+\n",
      "|      dms_timestamp| id|release_date|            name|color|description|            created|           modified|src_batch_id|\n",
      "+-------------------+---+------------+----------------+-----+-----------+-------------------+-------------------+------------+\n",
      "|2021-09-05 09:55:48|  5|  2021-08-01|Super Gadget 300|Black| new device|2021-09-05 06:55:48|2021-09-05 06:55:48|           0|\n",
      "|2021-09-05 09:55:48|  6|  2021-08-01|Super Gadget 300| Pink| new device|2021-09-05 06:55:48|2021-09-05 06:55:48|           0|\n",
      "|2021-09-05 09:55:54|  2|  2010-05-15|Super Gadget 100|Black|   update B|2010-03-21 12:00:02|2021-09-05 06:55:54|           0|\n",
      "|2021-09-05 09:55:54|  1|  2010-05-15|Super Gadget 100|  Red|   update A|2010-03-21 12:00:01|2021-09-05 06:55:54|           0|\n",
      "|2021-09-04 11:10:50|  4|  2018-05-13|Super Gadget 200|White|lorem ipsum|2018-03-20 12:01:01|2018-03-20 12:01:01|        null|\n",
      "|2021-09-04 11:10:50|  3|  2010-11-01|Super Gadget 100| Pink|lorem ipsum|2010-08-05 07:00:00|2010-08-05 07:00:00|        null|\n",
      "+-------------------+---+------------+----------------+-----+-----------+-------------------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.table(pm.hive).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "698aff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2021-09-05 08:36:12.056</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '6', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2021-09-05 08:33:42.188</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '4', 'numOutputBytes': '2565...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2021-09-05 08:11:36.572</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>6.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '6', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-09-05 08:09:46.490</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '4', 'numOutputBytes': '2565...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-09-05 07:58:08.388</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '6', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-09-05 07:57:57.204</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '4', 'numOutputBytes': '2565...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-09-05 07:55:16.306</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '6', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-09-05 07:49:52.616</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '4', 'numOutputBytes': '2565...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-09-05 07:37:56.039</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MERGE</td>\n",
       "      <td>{'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '6', 'numTargetRowsInserted'...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-05 06:17:53.575</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '4', 'numOutputBytes': '2569...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName  \\\n",
       "0        9 2021-09-05 08:36:12.056   None     None   \n",
       "1        8 2021-09-05 08:33:42.188   None     None   \n",
       "2        7 2021-09-05 08:11:36.572   None     None   \n",
       "3        6 2021-09-05 08:09:46.490   None     None   \n",
       "4        5 2021-09-05 07:58:08.388   None     None   \n",
       "5        4 2021-09-05 07:57:57.204   None     None   \n",
       "6        3 2021-09-05 07:55:16.306   None     None   \n",
       "7        2 2021-09-05 07:49:52.616   None     None   \n",
       "8        1 2021-09-05 07:37:56.039   None     None   \n",
       "9        0 2021-09-05 06:17:53.575   None     None   \n",
       "\n",
       "                           operation  \\\n",
       "0                              MERGE   \n",
       "1  CREATE OR REPLACE TABLE AS SELECT   \n",
       "2                              MERGE   \n",
       "3  CREATE OR REPLACE TABLE AS SELECT   \n",
       "4                              MERGE   \n",
       "5  CREATE OR REPLACE TABLE AS SELECT   \n",
       "6                              MERGE   \n",
       "7  CREATE OR REPLACE TABLE AS SELECT   \n",
       "8                              MERGE   \n",
       "9  CREATE OR REPLACE TABLE AS SELECT   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...  None     None      None   \n",
       "1  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "2  {'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...  None     None      None   \n",
       "3  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "4  {'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...  None     None      None   \n",
       "5  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "6  {'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...  None     None      None   \n",
       "7  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "8  {'matchedPredicates': '[{\"predicate\":\"(s.`Op` ...  None     None      None   \n",
       "9  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          8.0           None          False   \n",
       "1          7.0           None          False   \n",
       "2          6.0           None          False   \n",
       "3          5.0           None          False   \n",
       "4          4.0           None          False   \n",
       "5          3.0           None          False   \n",
       "6          2.0           None          False   \n",
       "7          1.0           None          False   \n",
       "8          0.0           None          False   \n",
       "9          NaN           None          False   \n",
       "\n",
       "                                    operationMetrics userMetadata  \n",
       "0  {'numOutputRows': '6', 'numTargetRowsInserted'...         None  \n",
       "1  {'numOutputRows': '4', 'numOutputBytes': '2565...         None  \n",
       "2  {'numOutputRows': '6', 'numTargetRowsInserted'...         None  \n",
       "3  {'numOutputRows': '4', 'numOutputBytes': '2565...         None  \n",
       "4  {'numOutputRows': '6', 'numTargetRowsInserted'...         None  \n",
       "5  {'numOutputRows': '4', 'numOutputBytes': '2565...         None  \n",
       "6  {'numOutputRows': '6', 'numTargetRowsInserted'...         None  \n",
       "7  {'numOutputRows': '4', 'numOutputBytes': '2565...         None  \n",
       "8  {'numOutputRows': '6', 'numTargetRowsInserted'...         None  \n",
       "9  {'numOutputRows': '4', 'numOutputBytes': '2569...         None  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DeltaTable.forName(spark, pm.hive)\n",
    "\n",
    "dt.history().toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
