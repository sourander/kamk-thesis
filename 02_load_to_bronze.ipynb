{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "from helpers.paths import PathMerger\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Spark Context\n",
    "\n",
    "If there would be dates prior to 1582-10-15, we would need to correct all dates before that to prolectic gregorian calendar using SparkSession configs:\n",
    "\n",
    "```python\n",
    "spark.conf.set(\"spark.sql.legacy.parquet.datetimeRebaseModeInRead\", \"CORRECTED\")\n",
    "spark.conf.set(\"spark.sql.legacy.parquet.int96RebaseModeInWrite\", \"CORRECTED\")\n",
    "```\n",
    "\n",
    "Spark assumes times to be in UTC. To apply tz shift, we can change this to another timezone:\n",
    "```python\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "         .appName('LoadDatasetsToBronze')\n",
    "         .config('spark.jars.packages', 'io.delta:delta-core_2.12:1.0.0')\n",
    "         .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension')\n",
    "         .config('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog')\n",
    "         .config('spark.sql.session.timeZone', 'UTC')\n",
    "         .config('spark.sql.parquet.compression.codec', 'None')\n",
    "         .getOrCreate())\n",
    "\n",
    "\n",
    "# This cannot be imported before initializing the SparkSession.\n",
    "from delta import DeltaTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion Settings\n",
    "\n",
    "These variables are hard-coded here, but in production, these should be placed into an ETL settings database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of combinations to create: (source_system, db, table)\n",
    "tables = [\n",
    "    ('abc', 'customers', 'customers'), \n",
    "    ('abc', 'customers', 'customer_details'),\n",
    "    ('abc', 'devices', 'device_models'),\n",
    "    ('abc', 'devices', 'devices')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset from Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "\n",
    "for _, db, table in tables:\n",
    "    \n",
    "    # Instantiate\n",
    "    pm = PathMerger(db, table)\n",
    "    \n",
    "    # Load the src table\n",
    "    df = (\n",
    "        spark\n",
    "        .read\n",
    "        .format('parquet')\n",
    "        .load(pm.staging)\n",
    "        # .withColumn('src_file', F.input_file_name())\n",
    "        .withColumn('src_batch_id', F.lit(None).cast('integer'))\n",
    "    )\n",
    "    \n",
    "    # Write to BRONZE\n",
    "    (\n",
    "        df\n",
    "        .write\n",
    "        .format('delta')\n",
    "        .mode('overwrite')\n",
    "        .option('overwriteSchema', 'true')\n",
    "        .option('path', os.path.abspath(pm.bronze))\n",
    "        .saveAsTable(pm.hive)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the Output\n",
    "\n",
    "All four tables have been written to bronze database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "|  bronze|abc_customers_cus...|      false|\n",
      "|  bronze|abc_customers_cus...|      false|\n",
      "|  bronze|abc_devices_devic...|      false|\n",
      "|  bronze| abc_devices_devices|      false|\n",
      "+--------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in bronze\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a table for further CDC studies\n",
    "\n",
    "For the next Notebooks, we will be focusing in the the `device_models` table. Reasoning for this is that the table has been manually written, so it is easy to examine the change data MERGE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files originated from:               S3\\staging\\dms\\abc\\devices\\device_models\n",
      "The Delta table is located at:           S3\\bronze\\abc\\devices\\device_models\n",
      "...and it can be called from Hive as:    bronze.abc_devices_devicemodels\n"
     ]
    }
   ],
   "source": [
    "pm = PathMerger('devices', 'device_models')\n",
    "\n",
    "w = 40\n",
    "\n",
    "print(\"The files originated from: \".ljust(w), pm.staging)\n",
    "print(\"The Delta table is located at: \".ljust(w), pm.bronze)\n",
    "print(\"...and it can be called from Hive as: \".ljust(w), pm.hive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Hive Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>data_type</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dms_timestamp</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id</td>\n",
       "      <td>bigint</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>release_date</td>\n",
       "      <td>date</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>color</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>description</td>\n",
       "      <td>string</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>created</td>\n",
       "      <td>timestamp</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>modified</td>\n",
       "      <td>timestamp</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>src_batch_id</td>\n",
       "      <td>int</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td># Partitioning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Not partitioned</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td># Detailed Table Information</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Name</td>\n",
       "      <td>bronze.abc_devices_devicemodels</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Location</td>\n",
       "      <td>file:/C:/Users/soura/PycharmProjects/opinnayte...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Provider</td>\n",
       "      <td>delta</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Table Properties</td>\n",
       "      <td>[Type=EXTERNAL,delta.minReaderVersion=1,delta....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        col_name  \\\n",
       "0                  dms_timestamp   \n",
       "1                             id   \n",
       "2                   release_date   \n",
       "3                           name   \n",
       "4                          color   \n",
       "5                    description   \n",
       "6                        created   \n",
       "7                       modified   \n",
       "8                   src_batch_id   \n",
       "9                                  \n",
       "10                # Partitioning   \n",
       "11               Not partitioned   \n",
       "12                                 \n",
       "13  # Detailed Table Information   \n",
       "14                          Name   \n",
       "15                      Location   \n",
       "16                      Provider   \n",
       "17              Table Properties   \n",
       "\n",
       "                                            data_type comment  \n",
       "0                                              string          \n",
       "1                                              bigint          \n",
       "2                                                date          \n",
       "3                                              string          \n",
       "4                                              string          \n",
       "5                                              string          \n",
       "6                                           timestamp          \n",
       "7                                           timestamp          \n",
       "8                                                 int          \n",
       "9                                                              \n",
       "10                                                             \n",
       "11                                                             \n",
       "12                                                             \n",
       "13                                                             \n",
       "14                    bronze.abc_devices_devicemodels          \n",
       "15  file:/C:/Users/soura/PycharmProjects/opinnayte...          \n",
       "16                                              delta          \n",
       "17  [Type=EXTERNAL,delta.minReaderVersion=1,delta....          "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE EXTENDED {pm.hive}\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the table using SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>description</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>src_batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Red</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Black</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Pink</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-08-05 07:00:00</td>\n",
       "      <td>2010-08-05 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>Super Gadget 200</td>\n",
       "      <td>White</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2018-03-20 12:01:01</td>\n",
       "      <td>2018-03-20 12:01:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dms_timestamp  id release_date              name  color  description  \\\n",
       "0  2021-09-11 11:30:04   1   2010-05-15  Super Gadget 100    Red  lorem ipsum   \n",
       "1  2021-09-11 11:30:04   2   2010-05-15  Super Gadget 100  Black  lorem ipsum   \n",
       "2  2021-09-11 11:30:04   3   2010-11-01  Super Gadget 100   Pink  lorem ipsum   \n",
       "3  2021-09-11 11:30:04   4   2018-05-13  Super Gadget 200  White  lorem ipsum   \n",
       "\n",
       "              created            modified  src_batch_id  \n",
       "0 2010-03-21 12:00:01 2010-03-21 12:00:01           NaN  \n",
       "1 2010-03-21 12:00:02 2010-03-21 12:00:02           NaN  \n",
       "2 2010-08-05 07:00:00 2010-08-05 07:00:00           NaN  \n",
       "3 2018-03-20 12:01:01 2018-03-20 12:01:01           NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM {pm.hive}\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the table using Python API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dms_timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>name</th>\n",
       "      <th>color</th>\n",
       "      <th>description</th>\n",
       "      <th>created</th>\n",
       "      <th>modified</th>\n",
       "      <th>src_batch_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Red</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>2010-03-21 12:00:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-15</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Black</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>2010-03-21 12:00:02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-11-01</td>\n",
       "      <td>Super Gadget 100</td>\n",
       "      <td>Pink</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2010-08-05 07:00:00</td>\n",
       "      <td>2010-08-05 07:00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-11 11:30:04</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-05-13</td>\n",
       "      <td>Super Gadget 200</td>\n",
       "      <td>White</td>\n",
       "      <td>lorem ipsum</td>\n",
       "      <td>2018-03-20 12:01:01</td>\n",
       "      <td>2018-03-20 12:01:01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dms_timestamp  id release_date              name  color  description  \\\n",
       "0  2021-09-11 11:30:04   1   2010-05-15  Super Gadget 100    Red  lorem ipsum   \n",
       "1  2021-09-11 11:30:04   2   2010-05-15  Super Gadget 100  Black  lorem ipsum   \n",
       "2  2021-09-11 11:30:04   3   2010-11-01  Super Gadget 100   Pink  lorem ipsum   \n",
       "3  2021-09-11 11:30:04   4   2018-05-13  Super Gadget 200  White  lorem ipsum   \n",
       "\n",
       "              created            modified  src_batch_id  \n",
       "0 2010-03-21 12:00:01 2010-03-21 12:00:01           NaN  \n",
       "1 2010-03-21 12:00:02 2010-03-21 12:00:02           NaN  \n",
       "2 2010-08-05 07:00:00 2010-08-05 07:00:00           NaN  \n",
       "3 2018-03-20 12:01:01 2018-03-20 12:01:01           NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.table(pm.hive)\n",
    "# OR spark.read.load(pm.bronze)\n",
    "# OR spark.sql(\"SELECT * FROM {pm.hive}\")\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access data using Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DeltaTable.forName(spark, pm.hive)\n",
    "# OR: DeltaTable.forPath(spark, pm.bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-12 06:26:03.746</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>CREATE OR REPLACE TABLE AS SELECT</td>\n",
       "      <td>{'description': None, 'partitionBy': '[]', 'pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '4', 'numOutputBytes': '2569...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName  \\\n",
       "0        0 2021-09-12 06:26:03.746   None     None   \n",
       "\n",
       "                           operation  \\\n",
       "0  CREATE OR REPLACE TABLE AS SELECT   \n",
       "\n",
       "                                 operationParameters   job notebook clusterId  \\\n",
       "0  {'description': None, 'partitionBy': '[]', 'pr...  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          NaN           None          False   \n",
       "\n",
       "                                    operationMetrics userMetadata  \n",
       "0  {'numOutputRows': '4', 'numOutputBytes': '2569...         None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.history().toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
